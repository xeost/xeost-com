---
title: '100 Intermediate AWS Interview Questions'
description: 'Advance your AWS knowledge with these 100 intermediate interview questions covering advanced concepts and services.'
pubDate: 2025-09-04
author: 'Xeost'
cover: assets/cover.jpeg
postType: 'coverTop'
recommend: false
tags: ['Interview Q&A', 'AWS']
draft: true
---

Take your AWS interview preparation to the next level with this list of 100 intermediate questions. From Auto Scaling to security best practices, get ready for deeper dives into Amazon Web Services.

## How does Auto Scaling work in AWS, and when should you use it?

**Overview of Auto Scaling**  
Auto Scaling in AWS automatically adjusts the number of EC2 instances in a fleet based on defined conditions, ensuring optimal performance and cost efficiency. It monitors metrics like CPU utilization, request counts, or custom metrics via CloudWatch, scaling out by adding instances during demand spikes or scaling in by removing them when demand drops.

**Key Components**  
It uses launch configurations or templates to define instance settings, such as AMI, instance type, and security groups. Auto Scaling groups specify minimum, maximum, and desired instance counts, plus scaling policies. Policies can be dynamic (based on metrics), scheduled, or predictive, leveraging machine learning for demand forecasting.

**How It Works**  
When a CloudWatch alarm triggers (e.g., CPU > 70%), Auto Scaling adjusts the instance count within the group’s limits. It distributes instances across Availability Zones for high availability and integrates with Elastic Load Balancers to route traffic efficiently.

**When to Use**  
Use Auto Scaling for applications with variable workloads, like e-commerce sites during sales or batch processing jobs. It ensures performance under load, minimizes costs by scaling down during low demand, and enhances fault tolerance by replacing unhealthy instances. Avoid it for static, predictable workloads where manual scaling suffices.

**Benefits**  
Auto Scaling optimizes costs, improves availability, and simplifies management, making it ideal for dynamic, scalable applications in AWS.

## What’s the difference between a Reserved Instance and a Savings Plan?

**Overview of Pricing Models**  
Reserved Instances (RIs) and Savings Plans are AWS cost-saving options for predictable workloads, offering discounts over On-Demand pricing. Both reduce costs but differ in flexibility and application.

**Reserved Instances**  
RIs commit you to specific instance types, regions, and operating systems for 1 or 3 years. You pay upfront (fully, partially, or no upfront) for significant discounts, up to 75%. They’re best for steady-state applications with fixed instance requirements, like specific EC2 types or RDS databases. However, RIs are less flexible, requiring you to match instance attributes precisely.

**Savings Plans**  
Savings Plans offer similar discounts (up to 72%) but provide more flexibility. You commit to a consistent spend amount (e.g., $10/hour) for 1 or 3 years, applicable across instance types, sizes, or even serverless services like Lambda. They come in Compute (region-agnostic, any compute service) or EC2 Instance Savings Plans (specific to EC2, single region). This flexibility suits dynamic workloads.

**Key Differences**  
RIs lock you into specific instance configurations, while Savings Plans prioritize spend commitment over instance specificity. Savings Plans cover more services, including Fargate and Lambda, and allow easier instance type changes. RIs may offer slightly higher discounts for predictable EC2 or RDS use.

**When to Choose**  
Choose RIs for fixed, long-term EC2/RDS needs; opt for Savings Plans for flexible, multi-service, or evolving workloads. Both optimize costs effectively.

## What is the difference between Security Groups and IAM roles?

**Purpose and Scope**  
Security Groups and IAM roles serve distinct purposes in AWS. Security Groups act as virtual firewalls for EC2 instances, controlling inbound and outbound traffic at the instance or ENI level. IAM roles, however, manage permissions, defining what actions AWS resources or users can perform on services.

**Security Groups Functionality**  
Security Groups operate at the network level, using rules to allow or deny traffic based on protocol, port, and source/destination (e.g., IP or another Security Group). They’re stateful, meaning allowed inbound traffic automatically permits return traffic. They’re ideal for securing network access to instances, like allowing HTTP on port 80.

**IAM Roles Functionality**  
IAM roles are identity-based, granting permissions to AWS services or users via policies. For example, an EC2 instance with an IAM role can access S3 buckets without hard-coded credentials. Roles are assumed temporarily by services or users, enhancing security through least privilege principles.

**Key Differences**  
Security Groups control network traffic (Layer 3/4), while IAM roles manage service-level permissions (API actions). Security Groups apply to resources like EC2 or RDS, whereas IAM roles apply to entities like EC2 instances, Lambda functions, or human users. Security Groups don’t manage resource actions; IAM roles don’t control network traffic.

**Use Case**  
Use Security Groups to secure network access; use IAM roles to define resource permissions securely. Both are critical for a robust AWS security posture.

## When would you choose RDS over DynamoDB?

**Database Type and Structure**  
RDS is a managed relational database service supporting SQL databases like MySQL, PostgreSQL, or Oracle, ideal for structured data with complex relationships. DynamoDB is a NoSQL database designed for unstructured or semi-structured data, offering high scalability and low-latency key-value or document storage.

**Use Cases for RDS**  
Choose RDS for applications requiring complex queries, joins, or transactions, such as ERP systems, e-commerce platforms with relational data, or reporting tools needing SQL compatibility. It supports structured schemas, ACID transactions, and is suited for applications with moderate, predictable workloads.

**Use Cases for DynamoDB**  
DynamoDB excels in high-traffic, scalable applications like gaming, IoT, or real-time analytics, where low-latency and massive scalability are critical. It handles unstructured data and auto-scales seamlessly but lacks native support for complex joins or transactions (though transactions are now supported with limitations).

**Key Decision Factors**  
Select RDS when you need relational data modeling, SQL-based querying, or integration with traditional business applications. Choose DynamoDB for serverless, high-scale, or event-driven applications with flexible schemas. RDS is better for predictable workloads with moderate scaling needs; DynamoDB suits dynamic, unpredictable traffic.

**Management and Cost**  
RDS requires more configuration (e.g., backups, patching), while DynamoDB is fully serverless. RDS may be costlier for high-scale workloads, whereas DynamoDB’s pay-per-use model suits variable demand. Choose based on data structure, query complexity, and scalability needs.

## How does CloudFormation help with infrastructure management?

**Infrastructure as Code**  
CloudFormation enables infrastructure management by defining AWS resources in templates (JSON or YAML). These templates describe resources like EC2 instances, S3 buckets, or VPCs, allowing automated, repeatable deployments.

**Key Features**  
It provisions and configures resources consistently, reducing manual errors. Templates support parameterization for flexibility across environments (e.g., dev, prod). CloudFormation handles resource dependencies, ensuring correct creation order, and supports updates or deletions via stack management.

**Benefits for Management**  
CloudFormation simplifies scaling and replicating infrastructure across regions or accounts. It tracks changes, enabling version control and rollback if needed. Integration with IAM ensures secure resource management, while drift detection identifies unauthorized changes. It’s ideal for managing complex, multi-resource setups like web applications or data pipelines.

**Use Cases**  
Use CloudFormation for consistent environment setups, disaster recovery, or multi-region deployments. It’s valuable when automating infrastructure for CI/CD pipelines or maintaining compliance through standardized templates. For simple setups, manual configuration might suffice, but CloudFormation excels in large, dynamic environments.

**Efficiency and Cost**  
By automating provisioning, it saves time and reduces misconfigurations. Templates can be reused, lowering setup costs. CloudFormation is free, though you pay for the resources it creates. It’s a powerful tool for backend developers to manage scalable, reproducible AWS infrastructure efficiently.

## What’s the difference between public and private subnets in a VPC?

**Subnet Basics**  
In an AWS VPC, subnets are segments of the VPC’s IP address range. Public and private subnets differ in their internet accessibility and routing configurations, impacting their use cases.

**Public Subnets**  
Public subnets have a route to an Internet Gateway, allowing instances to communicate directly with the internet. Instances in public subnets typically have public IPs or Elastic IPs and are used for resources like web servers or load balancers that require external access. Traffic is routed through the Internet Gateway for inbound and outbound communication.

**Private Subnets**  
Private subnets lack a direct route to the Internet Gateway, isolating instances from the public internet. They’re ideal for resources like databases or backend servers that don’t need external exposure. For internet access (e.g., for updates), private subnets use a NAT Gateway or NAT instance in a public subnet, routing outbound traffic securely.

**Key Differences**  
Public subnets enable direct internet communication; private subnets restrict it for security. Public subnets host publicly accessible resources, while private subnets protect sensitive workloads. Routing tables determine their behavior: public subnets point to an Internet Gateway, private ones don’t.

**Use Case Considerations**  
Use public subnets for front-end services requiring internet access. Choose private subnets for secure, internal resources like application servers or databases. This separation enhances security and supports multi-tier architectures in a VPC.

## What is the difference between Security Groups and Network ACLs?

**Purpose and Scope**  
Security Groups and Network ACLs (NACLs) are AWS security mechanisms for controlling traffic in a VPC, but they operate at different levels and serve distinct purposes.

**Security Groups**  
Security Groups act as instance-level firewalls, controlling inbound and outbound traffic for EC2 instances or other resources. They are stateful, meaning allowed inbound traffic automatically permits return traffic. Rules are allow-only (no explicit deny), based on protocols, ports, and sources (e.g., IP or Security Group). They’re applied to specific resources, offering granular control.

**Network ACLs**  
NACLs are subnet-level firewalls, controlling traffic entering or leaving a subnet. They are stateless, requiring explicit rules for both inbound and outbound traffic. NACLs support allow and deny rules, evaluated in order by rule number, and apply to all resources in a subnet. They’re useful for broad network control, like blocking specific IPs across a subnet.

**Key Differences**  
Security Groups are stateful and instance-specific, while NACLs are stateless and subnet-wide. Security Groups only allow traffic; NACLs can deny it. Security Groups are easier to manage for specific instances, while NACLs provide coarse-grained control at the subnet level.

**Use Case**  
Use Security Groups for fine-tuned instance access (e.g., allowing port 80 for web servers). Use NACLs for subnet-level restrictions, like denying specific IPs. Combining both ensures layered security in a VPC.

## How does Auto Scaling work in AWS?

**Functionality**  
Auto Scaling dynamically adjusts the number of EC2 instances based on defined conditions, ensuring performance and cost efficiency. It uses CloudWatch metrics (e.g., CPU usage, request counts) to trigger scaling actions, adding instances during demand spikes or removing them when demand drops.

**Components**  
Auto Scaling groups define minimum, maximum, and desired instance counts. Launch configurations or templates specify instance details (e.g., AMI, instance type). Scaling policies can be dynamic (metric-based), scheduled, or predictive, using machine learning to forecast demand.

**Process**  
When a CloudWatch alarm triggers (e.g., CPU > 70%), Auto Scaling adjusts the instance count within the group’s limits. It balances instances across Availability Zones for high availability and integrates with Elastic Load Balancers for traffic distribution. Unhealthy instances are automatically replaced.

**Benefits**  
It optimizes costs by scaling down during low demand, ensures performance under load, and enhances fault tolerance. Auto Scaling is ideal for variable workloads like e-commerce or batch processing, but less suited for static applications where manual scaling is sufficient.

## What are the different types of storage classes in S3?

**Overview of S3 Storage Classes**  
Amazon S3 offers multiple storage classes to optimize cost and performance based on data access patterns. Each class balances durability, availability, and retrieval costs.

**Standard**  
S3 Standard is for frequently accessed data, like active websites or analytics. It offers low latency and high throughput, ideal for high-performance needs, but costs more for storage.

**Standard-Infrequent Access (IA)**  
Standard-IA suits data accessed less often, like backups or older logs. It has lower storage costs than Standard but includes retrieval fees, making it cost-effective for infrequent access.

**One Zone-Infrequent Access (IA)**  
One Zone-IA stores data in a single Availability Zone, reducing costs further than Standard-IA. It’s for non-critical, infrequently accessed data, like secondary backups, with similar retrieval fees.

**Glacier**  
S3 Glacier is for archival data with retrieval times from minutes to hours. It’s low-cost for storage, ideal for long-term retention like compliance data, but retrieval costs apply.

**Glacier Deep Archive**  
Deep Archive is for rarely accessed data, like legal records, with retrieval times of 12-48 hours. It offers the lowest storage costs but highest retrieval fees.

**Intelligent-Tiering**  
Intelligent-Tiering automatically moves data between frequent and infrequent access tiers based on usage, with no retrieval fees. It’s best for unpredictable access patterns.

**Use Case**  
Choose based on access frequency and budget: Standard for active data, IA for backups, Glacier for archives, and Intelligent-Tiering for dynamic workloads. All maintain high durability.

## What is RDS, and how does it differ from DynamoDB?

**RDS Overview**  
Amazon RDS is a managed relational database service supporting engines like MySQL, PostgreSQL, and Oracle. It handles tasks like backups, patching, and scaling, ideal for structured data with complex queries and transactions.

**DynamoDB Overview**  
DynamoDB is a managed NoSQL database for unstructured or semi-structured data, offering low-latency, high-scalability key-value or document storage. It’s fully serverless, auto-scaling seamlessly for dynamic workloads.

**Key Differences**  
RDS uses relational schemas with SQL, supporting joins and ACID transactions, making it suitable for applications like ERP or e-commerce with structured data. DynamoDB uses flexible, schema-less models, excelling in high-traffic, event-driven apps like gaming or IoT, but lacks native complex joins (though transactions are supported with limits).

**Management and Scaling**  
RDS requires configuration for backups, replication, and scaling (e.g., read replicas, vertical scaling). DynamoDB is serverless, automatically handling scaling and maintenance, reducing operational overhead.

**Performance and Cost**  
RDS suits moderate, predictable workloads with higher management costs. DynamoDB excels in high-scale, unpredictable traffic with pay-per-use pricing, but costs can rise with heavy writes or reads.

**Use Case**  
Choose RDS for relational data, complex queries, or traditional applications. Opt for DynamoDB for scalable, low-latency, or serverless workloads with flexible schemas. Both ensure high availability, but the choice depends on data structure and access patterns.

## How do you secure an application hosted on AWS?

**Identity and Access Management**  
Use IAM roles and policies to enforce least privilege access for users and services. Assign roles to EC2 instances or Lambda functions to securely access resources like S3 or DynamoDB without hard-coded credentials.

**Network Security**  
Deploy applications in a VPC with private subnets for sensitive components like databases. Use Security Groups to control instance-level traffic (e.g., allow port 80 for web servers) and Network ACLs for subnet-level restrictions. Enable AWS WAF to protect against web attacks.

**Data Protection**  
Encrypt data at rest using AWS KMS for services like S3, RDS, or EBS. Use TLS/SSL for data in transit. Enable S3 bucket versioning and MFA delete for critical data protection.

**Monitoring and Logging**  
Enable AWS CloudTrail for auditing API calls and CloudWatch for monitoring application performance and security events. Set up alarms for suspicious activities, like unauthorized access attempts.

**Patch and Update Management**  
Regularly update AMIs, apply security patches to EC2 instances, and use managed services like RDS or Lambda, which AWS patches automatically. Enable AWS Systems Manager for automated patch management.

**Compliance and Best Practices**  
Use AWS Config to ensure compliance with security policies and AWS Trusted Advisor for best practice recommendations. Regularly review IAM policies and rotate credentials.

This multi-layered approach ensures robust security for AWS-hosted applications.

## What is cloud computing?

**Definition and Core Concept**  
Cloud computing delivers on-demand computing resources—servers, storage, databases, networking, software—over the internet, eliminating the need for on-premises infrastructure. It provides scalable, pay-as-you-go services hosted by providers like AWS.

**Key Characteristics**  
It offers scalability, allowing resources to adjust dynamically to demand. High availability ensures uptime through redundant systems. Flexibility supports diverse workloads, from web hosting to machine learning. Cost efficiency comes from paying only for used resources, avoiding upfront hardware costs.

**Service Models**  
Cloud computing includes three main models: Infrastructure as a Service (IaaS), like EC2, for raw compute resources; Platform as a Service (PaaS), like Elastic Beanstalk, for application deployment; and Software as a Service (SaaS), like Google Workspace, for end-user applications.

**Deployment Models**  
Public clouds (e.g., AWS) are shared, cost-effective platforms. Private clouds are dedicated to one organization for enhanced control. Hybrid clouds combine both, balancing cost and security.

**Benefits for Applications**  
Cloud computing simplifies management, enabling rapid deployment and scaling for applications. It supports global reach, fault tolerance, and automated updates, ideal for dynamic workloads like e-commerce or data analytics.

**Use Case**  
Use cloud computing for cost-efficient, scalable infrastructure, such as hosting web applications, running serverless functions, or storing backups. It’s critical for modern, agile development, ensuring flexibility and reliability.

## What is an Amazon VPC, and why is it used?

**Definition and Purpose**  
Amazon VPC (Virtual Private Cloud) is a logically isolated network within AWS, allowing you to define a virtual network environment with control over IP ranges, subnets, and routing. It provides a secure, customizable space for AWS resources.

**Key Features**  
VPC enables configuration of subnets (public or private), route tables, and gateways (e.g., Internet Gateway, NAT Gateway). You control network access using Security Groups and Network ACLs. VPC supports connectivity options like VPNs or Direct Connect for hybrid setups.

**Why It’s Used**  
VPC is used to isolate and secure resources, ensuring sensitive workloads like databases run in private subnets with no direct internet access. It enables multi-tier architectures (e.g., web servers in public subnets, databases in private) for scalability and security. VPC ensures compliance by restricting traffic and encrypting data flows.

**Benefits**  
It provides granular control over network configurations, enhancing security through isolation and access controls. VPC supports high availability across Availability Zones and integrates with AWS services like EC2, RDS, or Lambda. It’s essential for applications requiring secure, scalable, or hybrid network environments.

**Use Case**  
Use VPC for hosting web applications, securing sensitive data, or connecting on-premises systems to AWS. It’s critical for enterprises needing customized, secure, and scalable network infrastructure in the cloud.

## How would you connect an on-premises network to AWS?

**Connection Options**  
To connect an on-premises network to AWS, use AWS Direct Connect for dedicated, high-bandwidth connections or AWS Site-to-Site VPN for secure, encrypted connections over the internet.

**AWS Direct Connect**  
Direct Connect provides a private, dedicated network link between your on-premises data center and an AWS Direct Connect location. It offers consistent, low-latency performance, ideal for large data transfers or latency-sensitive applications. Set up a virtual interface (public or private) to access AWS services like VPC.

**Site-to-Site VPN**  
A Site-to-Site VPN creates an encrypted tunnel over the internet between your on-premises network and a VPC. It uses Virtual Private Gateways on the AWS side and a customer gateway on-premises. It’s cost-effective for smaller-scale or temporary connectivity but depends on internet reliability.

**Implementation Steps**  
Configure a VPC with private and public subnets. For Direct Connect, partner with an AWS Direct Connect provider to establish a physical connection. For VPN, set up IPsec tunnels with compatible on-premises hardware. Use route tables to direct traffic and Security Groups or NACLs for access control.

**Use Case and Benefits**  
Choose Direct Connect for high-throughput, stable connections (e.g., enterprise applications). Use VPN for quick, cost-effective setups (e.g., dev environments). Both enable hybrid architectures, secure data transfer, and access to AWS services from on-premises systems.

## What is the difference between EC2 instance types?

**Overview of EC2 Instance Types**  
Amazon EC2 offers various instance types optimized for different workloads, categorized by their compute, memory, storage, and networking capabilities.

**General Purpose**  
General-purpose instances (e.g., T3, M5) balance compute, memory, and networking. They suit diverse applications like web servers, small databases, or dev environments. T3 offers burstable performance for cost savings, while M5 is ideal for consistent workloads.

**Compute Optimized**  
Compute-optimized instances (e.g., C5, C6g) prioritize high-performance CPUs for compute-intensive tasks like batch processing, gaming servers, or scientific modeling. They offer high core counts and clock speeds.

**Memory Optimized**  
Memory-optimized instances (e.g., R5, X1) provide high RAM for memory-intensive applications like in-memory databases (e.g., SAP HANA), big data analytics, or caching systems. They ensure fast data access.

**Storage Optimized**  
Storage-optimized instances (e.g., I3, D3) focus on high-performance storage for large-scale databases, data warehouses, or distributed file systems. They offer high IOPS and low-latency storage options like NVMe SSDs.

**Accelerated Computing**  
Accelerated computing instances (e.g., P4, G4) use GPUs or FPGAs for tasks like machine learning, video rendering, or cryptocurrency mining. They excel in parallel processing workloads.

**Choosing an Instance**  
Select based on workload: general-purpose for mixed tasks, compute for CPU-heavy jobs, memory for RAM-intensive apps, storage for I/O needs, or accelerated for GPU tasks. Consider cost, scalability, and performance requirements.

## How do you choose between EBS and EFS?

**Overview**  
EBS (Elastic Block Store) and EFS (Elastic File System) are AWS storage services, but EBS provides block-level storage for single instances, while EFS offers shared file storage across multiple instances.

**EBS Features**  
EBS acts like virtual hard drives, attaching to one EC2 instance (multi-attach for NVMe volumes). It supports high-performance SSD (gp3, io2) or HDD volumes, snapshots for backups, and encryption. Ideal for databases or boot volumes requiring low-latency I/O.

**EFS Features**  
EFS is a scalable, managed NFS file system accessible by multiple EC2 instances across Availability Zones. It auto-scales capacity, supports thousands of concurrent connections, and offers storage classes (Standard, IA) for cost optimization. It’s POSIX-compliant for Unix-like environments.

**Key Differences**  
EBS is instance-specific, high-performance for single-use cases, with fixed attachment. EFS is shared, regionally available, and scales dynamically but has higher latency and cost for frequent access. EBS uses block I/O; EFS uses file I/O.

**Decision Factors**  
Choose EBS for single-instance apps, databases (e.g., MySQL), or workloads needing raw performance and snapshots. Opt for EFS for shared access in distributed apps, like content repositories, media processing, or big data analytics (e.g., Hadoop). Consider cost: EBS is cheaper for low-scale; EFS suits variable, shared needs.

**Use Case**  
EBS for isolated storage; EFS for collaborative, multi-instance file sharing. Evaluate performance, scalability, and sharing requirements.

## What is the difference between RDS and DynamoDB?

**Overview**  
Amazon RDS is a managed relational database service for SQL-based databases like MySQL or PostgreSQL. DynamoDB is a managed NoSQL database for key-value or document data, designed for high scalability and low latency.

**Data Structure**  
RDS uses structured schemas with tables, supporting complex SQL queries, joins, and ACID transactions. It’s ideal for applications like ERP or e-commerce with relational data. DynamoDB uses flexible, schema-less models, suited for unstructured data in apps like gaming or IoT, but lacks native complex joins (supports limited transactions).

**Management**  
RDS automates backups, patching, and replication but requires configuration for scaling (e.g., read replicas). DynamoDB is fully serverless, auto-scaling with no maintenance, simplifying operations for dynamic workloads.

**Performance and Scalability**  
RDS offers predictable performance for moderate workloads, with vertical or read-replica scaling. DynamoDB excels in high-scale, low-latency scenarios, auto-scaling seamlessly for unpredictable traffic.

**Cost Considerations**  
RDS has fixed costs for instances and storage, higher for heavy scaling. DynamoDB’s pay-per-use model suits variable workloads but can be costly for high read/write throughput.

**Use Case**  
Choose RDS for structured data, complex queries, or traditional applications. Select DynamoDB for scalable, serverless, or event-driven apps with flexible schemas. The decision hinges on data structure, query needs, and scalability requirements.

## How do you ensure database backups in AWS?

**Automated Backups with RDS**  
For Amazon RDS, enable automated backups to capture daily snapshots and transaction logs, stored in S3. Configure backup retention (up to 35 days) and schedule during low-traffic windows. RDS supports point-in-time recovery for granular restoration.

**Manual Snapshots**  
Create manual snapshots in RDS or DynamoDB for specific recovery points, like before major updates. Snapshots are stored in S3, encrypted by default if the database is encrypted. Copy snapshots across regions for disaster recovery.

**DynamoDB Backup Options**  
For DynamoDB, use on-demand backups for full table copies or enable point-in-time recovery (PITR) for continuous backups, allowing restoration within a 35-day window. Backups are stored securely and can be restored to new tables.

**Cross-Region Replication**  
Use RDS read replicas or DynamoDB global tables for cross-region replication, ensuring data availability during regional failures. RDS read replicas can be promoted to standalone databases if needed.

**Security and Monitoring**  
Encrypt backups using AWS KMS for security. Use CloudTrail to audit backup actions and CloudWatch to monitor backup success or failures. Tag backups for easy management and compliance.

**Best Practices**  
Schedule automated backups for production databases, supplement with manual snapshots for critical changes, and test restores periodically. Use cross-region replication for high availability. This ensures data durability, security, and recoverability for AWS databases.

## What is Infrastructure as Code (IaC), and how does AWS support it?

**Definition of IaC**  
Infrastructure as Code (IaC) is the practice of managing and provisioning infrastructure through machine-readable definition files, enabling automated, repeatable, and version-controlled deployments. It treats infrastructure like software, reducing manual errors and improving consistency.

**AWS Support for IaC**  
AWS provides tools like CloudFormation and AWS CDK (Cloud Development Kit) to implement IaC. CloudFormation uses JSON or YAML templates to define resources like EC2, S3, or VPCs, automating their creation, update, or deletion. CDK allows developers to write IaC in programming languages (e.g., Python, TypeScript) for more flexibility and abstraction.

**Key Benefits**  
CloudFormation ensures consistent resource provisioning across environments (e.g., dev, prod) and supports stack management for updates or rollbacks. CDK simplifies complex templates with reusable constructs. Both integrate with IAM for secure access control and CloudTrail for auditing changes.

**Additional Tools**  
AWS supports other IaC tools like Terraform through compatibility with AWS APIs. AWS OpsWorks uses Chef or Puppet for configuration management, complementing IaC for application-layer automation. CloudWatch monitors IaC-deployed resources, ensuring performance and compliance.

**Use Case**  
Use IaC for deploying scalable web applications, disaster recovery setups, or multi-region infrastructure. It streamlines management, enables version control, and supports CI/CD pipelines, making it essential for agile, automated AWS environments.

## How do you secure sensitive data in AWS?

**Encryption**  
Encrypt sensitive data at rest using AWS Key Management Service (KMS) for services like S3, EBS, or RDS. Use TLS/SSL for data in transit to secure communication. Enable encryption for S3 buckets, RDS instances, and EFS file systems by default.

**Access Control**  
Implement least privilege with IAM roles and policies. Assign roles to EC2 instances or Lambda functions to access resources without hard-coded credentials. Use S3 bucket policies and IAM to restrict access to sensitive data.

**Network Security**  
Place resources in a VPC with private subnets to isolate sensitive data. Use Security Groups to control instance-level traffic and Network ACLs for subnet-level restrictions. Enable AWS WAF to protect web applications from attacks.

**Data Protection**  
Enable S3 versioning and MFA delete to prevent accidental data loss. Use AWS Backup for automated, encrypted backups of RDS, DynamoDB, or EFS. Replicate data across regions for disaster recovery using services like S3 Cross-Region Replication.

**Monitoring and Auditing**  
Use CloudTrail to log API access to sensitive data and CloudWatch to monitor unauthorized access attempts. Enable AWS Config to track configuration changes and ensure compliance.

**Best Practices**  
Rotate encryption keys regularly via KMS. Use AWS Secrets Manager for secure credential storage. Regularly audit IAM policies and test data recovery processes to ensure robust protection of sensitive data in AWS.

## How do you monitor and audit AWS resources?

**Monitoring with CloudWatch**  
Use Amazon CloudWatch to monitor AWS resources in real-time. It collects metrics (e.g., CPU utilization for EC2), logs from applications or services, and custom metrics. Set up dashboards for visualization and alarms to trigger actions like notifications via SNS or Auto Scaling. For advanced monitoring, enable CloudWatch Logs Insights for querying logs.

**Auditing with CloudTrail**  
CloudTrail records all API calls and account activity, creating an audit trail for security and compliance. It logs events like IAM changes or S3 access, stored in S3 buckets. Enable multi-account trails for organization-wide auditing and integrate with CloudWatch Events for alerts on suspicious activities.

**Integration and Additional Tools**  
Combine CloudWatch with X-Ray for distributed tracing in applications. Use AWS Config to assess resource configurations against best practices and track changes over time. For security-focused auditing, integrate with GuardDuty for threat detection.

**Best Practices**  
Set retention policies for logs (e.g., 90 days for CloudTrail). Enable detailed monitoring for critical resources and test alarms regularly. Use IAM roles to control access to monitoring data. This setup ensures proactive issue detection, compliance, and operational efficiency for AWS resources.

## How do you optimize costs in AWS?

**Use Cost-Effective Services**  
Leverage AWS services like EC2 Spot Instances for interruptible workloads, saving up to 90% over On-Demand. Use Savings Plans or Reserved Instances for predictable workloads, offering discounts up to 72%. Opt for serverless services like Lambda or Fargate to pay only for usage.

**Right-Sizing Resources**  
Monitor usage with AWS Trusted Advisor and CloudWatch to identify over-provisioned resources. Downsize EC2 instances or RDS databases to match actual demand. Use Auto Scaling to adjust capacity dynamically, avoiding idle resources.

**Storage Optimization**  
Choose appropriate S3 storage classes: Standard for frequent access, Infrequent Access (IA) for backups, or Glacier for archives. Enable S3 Lifecycle policies to transition data to cheaper classes automatically. Use EBS gp3 volumes for cost-efficient, high-performance storage.

**Monitoring and Budgeting**  
Use AWS Cost Explorer to analyze spending patterns and forecast costs. Set budgets in AWS Budgets to receive alerts for overspending. Tag resources for granular cost tracking and allocate costs to projects or teams.

**Eliminate Waste**  
Stop or terminate unused EC2 instances, EBS volumes, or Elastic IPs. Enable auto-scaling for dynamic workloads and schedule non-production resources to shut down during off-hours using AWS Instance Scheduler.

**Best Practices**  
Regularly review Cost Explorer reports, optimize instance types, and use AWS Pricing Calculator for planning. Combining these strategies ensures cost efficiency while maintaining performance in AWS.

## How would you migrate an on-premises application to AWS?

**Assessment and Planning**  
Evaluate the application’s architecture, dependencies, and requirements. Use AWS Application Discovery Service to inventory on-premises resources. Identify workload type (e.g., web app, database) and define migration strategy: rehost, replatform, or refactor.

**Choose Migration Tools**  
Use AWS Server Migration Service (SMS) or CloudEndure Migration for rehosting servers to EC2. For databases, leverage AWS Database Migration Service (DMS) to migrate to RDS or Aurora. For large data transfers, use AWS Snowball for offline or Transfer Acceleration for online transfers.

**Set Up AWS Environment**  
Create a VPC with public and private subnets for security and scalability. Configure IAM roles, Security Groups, and Network ACLs to secure resources. Set up target services like EC2, RDS, or Elastic Beanstalk based on the application’s needs.

**Execute Migration**  
Rehost by lifting and shifting servers to EC2 using SMS or VM Import/Export. Replatform by moving to managed services (e.g., RDS for databases). Refactor to serverless (e.g., Lambda) for modernization. Test connectivity and performance post-migration.

**Optimization and Validation**  
Validate application functionality using CloudWatch for monitoring and X-Ray for tracing. Optimize costs with right-sized instances or Savings Plans. Enable backups (e.g., RDS snapshots) and auto-scaling for resilience.

**Best Practices**  
Start with a pilot migration, use automation tools, and document the process. Ensure minimal downtime with staged migrations and test thoroughly to confirm performance and security in AWS.

## How does Auto Scaling work in AWS?

## What is a VPC, and how do you secure it?

## What is CloudFormation and how is it used?

## What’s the difference between CloudWatch and CloudTrail?

## How do you handle secrets management in AWS?

## What are lifecycle policies in S3?

## Explain the key components of AWS.

## What is an EC2 instance and how does it work?

## Describe the difference between S3 and EBS in AWS.

## How does Auto Scaling work in AWS?

## What is the AWS Free Tier, and what services are included?

## What are key-pairs in AWS?

## What is Elastic Load Balancing (ELB) and how does it function?

## What are the various load balancers provided by AWS?

## How is data transfer handled in AWS?

## What is Amazon RDS, and what database engines does it support?

## Explain the concept of AWS Identity and Access Management (IAM).

## What is Amazon VPC and how does it help in securing your resources?

## How many subnets can a VPC contain?

## Describe the use of Amazon Route 53.

## How does AWS handle disaster recovery and backup?

## What is AWS Elastic Beanstalk, and how does it simplify application deployment?

## Explain the significance of AWS Organizations in managing multiple AWS accounts.

## What is an AMI in AWS and why is it used?

## What is the relationship between regions and availability zones in AWS?

## What is the maximum size of an object in S3?

## Describe the difference between Amazon S3 and EBS.

## How does AWS Lambda work, and what are its use cases?

## What are security groups and NACLs in the context of AWS VPC?

## Explain the purpose of AWS CloudFormation.

## How do you monitor and log AWS resources?

## Discuss the various storage classes in Amazon S3.

## What is AWS OpsWorks, and how does it work?

## Explain AWS Key Management Service (KMS) and its use cases.

## How does AWS support hybrid cloud architectures?

## What is the significance of Amazon DynamoDB in AWS?

## What is AWS Elastic Transcoder, and when would you use it?

## Discuss the use of AWS CodeDeploy in application deployment.

## Explain the purpose of AWS CloudTrail.

## How do you configure and manage AWS Elastic Load Balancers?

## What is the AWS Marketplace, and how is it beneficial for users?

## What is the difference between Application Load Balancer and Network Load Balancer?

## What is the difference between vertical and horizontal scaling in AWS?

## Discuss the use of Amazon ECS (Elastic Container Service) in container management.

## Explain the concept of AWS Direct Connect.

## How do you troubleshoot performance issues in an AWS environment?

## What is AWS Snowball, and when would you use it?

## How does AWS support DevOps practices?

## Discuss the use of AWS CloudWatch in monitoring resources.

## How do you handle version control in Amazon S3?

## What is AWS Glue, and how does it simplify the ETL process?

## Explain the concept of AWS Step Functions.

## Discuss the benefits of using Amazon CloudFront.

## How does AWS handle security in a multi-tenant environment?

## What is Amazon Kinesis, and how is it used for real-time data streaming?

## What are the different types of EC2 instances based on their costs?

## What is the relation between the Availability Zone and Region?

## How do you monitor Amazon VPC?

## What are the different types of EC2 instances based on their costs?

## What do you understand by stopping and terminating an EC2 Instance?

## What are the consistency models for modern DBs offered by AWS?

## What is Geo-Targeting in CloudFront?

## What are the advantages of AWS IAM?

## What do you understand by a Security Group?

## What are Spot Instances and On-Demand Instances?

## Explain Connection Draining.

## What is a Stateful and a Stateless Firewall?

## What is a Power User Access in AWS?

## What is an Instance Store Volume and an EBS Volume?

## What are Recovery Time Objective and Recovery Point Objective in AWS?

## Is there a way to upload a file that is greater than 100 Megabytes in Amazon S3?

## Can you change the Private IP Address of an EC2 instance while it is running or in a stopped state?

## What is the use of lifecycle hooks is Autoscaling?

## What are the policies that you can set for your user’s passwords?

## Which of the following statements is correct?

## Which of the following is a means for accessing human researchers or consultants to help solve problems on a contractual or temporary basis?

## Where does a user specify the maximum number of instances with the auto-scaling commands?
